<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="icon" href="/favicon.ico">

  <title>
    Stanford CS 149 - Yang Yan
  </title>

  <meta name="description" content="Parallel Computing" /><meta name="generator" content="Hugo 0.121.1">

  <link rel="stylesheet" href="/main.css" />

  
  
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.css"
      integrity="sha384-D+9gmBxUQogRLqvARvNLmA9hS2x//eK1FhVb9PiU86gmcrBrJAQT8okdJ4LMp2uv"
      crossorigin="anonymous"
    >

    <script defer
      src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/katex.min.js"
      integrity="sha384-483A6DwYfKeDa0Q52fJmxFXkcPCFfnXMoXblOkJ4JcA8zATN6Tm78UNL72AKk+0O"
      crossorigin="anonymous"
    ></script>

    <script defer
      src="https://cdn.jsdelivr.net/npm/katex@0.10.0-rc.1/dist/contrib/auto-render.min.js"
      integrity="sha384-yACMu8JWxKzSp/C1YV86pzGiQ/l1YUfE8oPuahJQxzehAjEt2GiQuy/BIvl9KyeF"
      crossorigin="anonymous"
      onload="renderMathInElement(document.body);">
    </script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
            delimiters: [
                {left: "$$", right: "$$", display: true},
                {left: "$", right: "$", display: false}
            ]
        });
    });
    </script>
  

  <meta property="og:title" content="Stanford CS 149" />
<meta property="og:description" content="Parallel Computing" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://yan99.github.io/notes/cs149/" /><meta property="article:section" content="Notes" />





  <meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Stanford CS 149"/>
<meta name="twitter:description" content="Parallel Computing"/>


  <meta itemprop="name" content="Stanford CS 149">
<meta itemprop="description" content="Parallel Computing">

<meta itemprop="wordCount" content="1706">
<meta itemprop="keywords" content="" />

  <meta itemprop="name" content="Stanford CS 149">
<meta itemprop="description" content="Parallel Computing">

<meta itemprop="wordCount" content="1706">
<meta itemprop="keywords" content="" />
</head><body class="flex relative h-full min-h-screen"><aside
  class="will-change-transform transform transition-transform -translate-x-full absolute top-0 left-0 md:relative md:translate-x-0 w-3/4 md:basis-60 h-full min-h-screen p-3 bg-slate-50 dark:bg-slate-800 border-r border-slate-200 dark:border-slate-700 flex flex-col gap-2.5 z-20 sidebar flex-shrink-0">
  <p class="font-bold mb-5 flex items-center gap-2">
    <button aria-label="Close sidebar"
      class="md:hidden menu-trigger-close p-1 rounded text-slate-800 dark:text-slate-50 hover:bg-slate-200 dark:hover:bg-slate-700"><svg class="h-6 w-6" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor"
  fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" />
  <line x1="18" y1="6" x2="6" y2="18" />
  <line x1="6" y1="6" x2="18" y2="18" />
</svg></button>
    <a href="https://yan99.github.io/" class="px-2">
      <span>Yang Yan</span>
    </a>
    <button aria-label="Toggle dark mode"
      class="dark-mode-toggle p-2 rounded border dark:border-slate-700 hover:bg-slate-200 dark:hover:bg-slate-700"><svg class="h-4 w-4" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor"
  fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" />
  <circle cx="12" cy="12" r="4" />
  <path d="M3 12h1M12 3v1M20 12h1M12 20v1M5.6 5.6l.7 .7M18.4 5.6l-.7 .7M17.7 17.7l.7 .7M6.3 17.7l-.7 .7" />
</svg></button>
  </p>

  
  <ul class="list-none flex flex-col gap-1">
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between  hover:bg-slate-200 dark:hover:bg-slate-700 "
        href="/" >
        <span>Home</span>
        
      </a>
    </li>
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between  text-slate-400 font-semibold pb-0 pl-1 border-b cursor-default pointer-events-none "
        href="#" >
        <span>Content</span>
        
      </a>
    </li>
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between  hover:bg-slate-200 dark:hover:bg-slate-700 "
        href="/notes/" >
        <span>Course Notes</span>
        
      </a>
    </li>
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between  hover:bg-slate-200 dark:hover:bg-slate-700 "
        href="/othernotes/" >
        <span>Other Notes</span>
        
      </a>
    </li>
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm flex items-center justify-between  hover:bg-slate-200 dark:hover:bg-slate-700 "
        href="/projects/" >
        <span>Projects</span>
        
      </a>
    </li>
    
  </ul>

  <div class="flex-1"></div>

  

  <ul class="list-none flex flex-wrap justify-center gap-1 pt-2 border-t border-slate-200 dark:border-slate-600">
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50  hover:bg-slate-200 dark:hover:bg-slate-700 "
        href="" target="_blank" rel="noopener noreferrer">
        <span class="sr-only">Github</span>
        
      </a>
    </li>
    
    <li>
      <a class="px-2 py-1.5 rounded-md text-sm block text-slate-800 dark:text-slate-50  hover:bg-slate-200 dark:hover:bg-slate-700 "
        href="" target="_blank" rel="noopener noreferrer">
        <span class="sr-only">LinkedIn</span>
        
        <span><svg class="h-4 w-4" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
  stroke-linecap="round" stroke-linejoin="round">
  <path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z" />
  <rect x="2" y="9" width="4" height="12" />
  <circle cx="4" cy="4" r="2" />
</svg></span>
        
      </a>
    </li>
    
  </ul>
</aside>

<div
  class="fixed bg-slate-700 bg-opacity-5 transition duration-200 ease-in-out inset-0 z-10 pointer-events-auto md:hidden left-0 top-0 w-full h-full hidden menu-overlay">
</div>

<button aria-label="Toggle Sidebar"
  class="md:hidden absolute top-3 left-3 z-10 menu-trigger p-1 rounded text-slate-800 dark:text-slate-50 hover:bg-slate-100"><svg class="h-6 w-6" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor"
  fill="none" stroke-linecap="round" stroke-linejoin="round">
  <path stroke="none" d="M0 0h24v24H0z" />
  <line x1="4" y1="6" x2="20" y2="6" />
  <line x1="4" y1="12" x2="20" y2="12" />
  <line x1="4" y1="18" x2="16" y2="18" />
</svg></button>





<div class="flex max-h-screen relative overflow-y-auto h-full w-full">
  
  <article class="px-6 py-20 w-full mx-auto prose lg:prose-lg dark:prose-invert h-fit prose-img:mx-auto">
    
    <a href="https://yan99.github.io/notes/" class="!no-underline !text-slate-500 !mb-2 !inline-block !font-normal !text-sm hover:!text-slate-700 dark:hover:!text-slate-400">‚Üê Back to list</a>

    
    <h1 class="!mb-2">Stanford CS 149</h1>
    

    

    <h2 id="introduction">Introduction</h2>
<h3 id="overall">Overall</h3>
<ul>
<li>Parallel thinking
<ol>
<li>Decomposing work into pieces that can safely be performed in parallel</li>
<li>Assigning work to processors</li>
<li>Managing communication/synchronization between the processors so that it does not limit speedup</li>
</ol>
</li>
<li>Writing code
<ul>
<li>Performance characteristics of implementation</li>
<li>Design trade-offs: performance vs. convenience vs. cost</li>
<li>Hardware</li>
</ul>
</li>
<li>Fast != efficient
<ul>
<li>Fast on parallel computer does not mean that it is using the hardware efficiently</li>
<li>Make use of provided machine capabilities (Programmer&rsquo;s perspective) vs choosing the right capabilities to put in system (HW designer&rsquo;s perspective)</li>
</ul>
</li>
<li>Why parallel: recent 15 years, processor performance improved on exploiting instruction-level parallelism and increasing CPU clock frequency</li>
</ul>
<h3 id="machine-code">Machine code</h3>
<ul>
<li>Structure: fetch/decode $\rightarrow$ ALU (execution unit) $\rightarrow$ execution context (Registers)</li>
<li>ALU: performs the operation</li>
<li>Registers: maintain program state; store value of variables</li>
</ul>
<h3 id="instruction-level-parallelism-ilp">Instruction level parallelism (ILP)</h3>
<ul>
<li>Superscalar execution:
<ul>
<li>Processor automatically find independent instructions in an instruction sequence and executes them in parallel on multiple execution units</li>
<li>Superscalar processor: decode and execute multiple instructions per clock</li>
<li>Out-of-order control logic $\rightarrow$ fetch/decode 1 // fetch/decode 2 $\rightarrow$ execution 1 // execution 2 $\rightarrow$ execution context</li>
<li>Ex. Old Intel Pentium 4 CPU: instruction decoder has 2 simple instruction decoders, and 1 complex instruction decoder; 2 integer units, 1 floating-point unit, and 1 memory interface unit in execution unit block</li>
<li>Number of ILP referring to depth of the instruction graph</li>
</ul>
</li>
</ul>
<h3 id="hardware-background-info">Hardware background info</h3>
<ul>
<li>Diminishing returns of super scalar execution when over 4 instructions issue to a processor per clock</li>
<li>Moore&rsquo;s Law: no. of transistors on microchips doubles every two years</li>
<li>ILP tapped out after around 2001; processor clock rate stops increasing after around 2005</li>
<li>Building faster processors by adding more execution units that run in parallel or units that are specialized for a specific task (graphic, audio/video playback, etc.)
<ul>
<li>Ex. multi-core CPU: Intel &ldquo;Comet Lake&rdquo; i9 10-core CPU, AMD Ryzen Threaddripper 3990X 64 core (4 8-core chiplets),  NVIDIA AD102 GPU, GPU-accelerated supercomputing, Apple A15 Bionic 6-core CPU multi-core GPU, Raspberry Pi 3 quad-core ARM A53 CPU</li>
</ul>
</li>
<li>Specialized processing is ubiquitous in mobile systems
<ul>
<li>Apple-designed multi-core GPU: neural engine (NPU) for DNN acceleartion + image/video encode/decode processor + motion(sensor) processor, TPU: tensor processing unit, a specialized processor for ML computations</li>
<li>Specialized hardware to accelerate DNN inference/training: Google TPU3, GraphCore IPU, Intel deep learning inference accelerator, Apple neural engine</li>
</ul>
</li>
<li>Software must be written to be parallel to see performance gains.</li>
</ul>
<h3 id="power-wall">Power wall</h3>
<ul>
<li>Power consumed by a trasistaor: dynamic power $\propto$ capacitive load, voltage<sup>2</sup>, frequency</li>
<li>Static power: transistors burn power even when inactive due to leakage</li>
<li>High power = high heat</li>
</ul>
<h3 id="memory">Memory</h3>
<p>Efficient processing almost always comes down to accessing data efficiently</p>
<ul>
<li>Memory is organized as an array of bytes; each byte is identified by its address in memory</li>
<li>Terminology
<ul>
<li>Memory access latency: the amount of time it takes the memory system to provide data to the processor</li>
<li>Stalls: a processor stalls (can&rsquo;t make progress) when it cannot run the next instruction in an instruction stream because future instructions depend on a previous instruction that is not yet complete. $\rightarrow$ accessing memory is a major source of stalls</li>
<li>Memory access times $~100$&rsquo;s of cycles (measure of latency)</li>
<li>Caches
<ul>
<li>A cache is a hardware implementation detail that does not impact the output of a program, only its performance</li>
<li>Cache is on-chip storage that maintains a copy of a subset of the values in memory</li>
<li>Cache memory can be load/store more quickly than in DRAM (dynmamic random access memory) (on Kaby Lake CPU, latency on caches range from 4 to 38, DRAM around 248)</li>
<li>Caches operate at the granularity of &ldquo;cache lines&rdquo;; Each line holds 4 bytes of data</li>
<li>LRU (least recently used) replacement policy</li>
<li>Spatial locality: loading data in a cache line &ldquo;preloads&rdquo; the data needed for subsequent accesses to <u>different addresses</u> in the same line, leading to cache hits; those instructions which are <u>stored nearby</u> to the recently executed instruction have high chances of execution.</li>
<li>Temporal locality: repeated accesses to the <u>same address</u> result in hits; a instruction which is <u>recently</u> executed have high chances of execution again.</li>
<li>Caches reduce length of stalls; caches provide high bandwidth data transfer</li>
</ul>
</li>
</ul>
</li>
<li>Implementation of the linear memory address space abstraction on a modern computer
<ul>
<li>Common organization: hierarchy of caches: level 1 (L1, 32 KB), level 2 (L2, 256 KB), level 3 (L3, 20 MB); DRAM (64 GB)</li>
<li>The instruction &ldquo;load the value stored at address X into register R0&rdquo; might involve a complex sequence of operations by multiple data caches and access to DRAM</li>
</ul>
</li>
</ul>
<h3 id="summary">Summary</h3>
<ul>
<li>Single-thread-of-control performance is improving very slowly
<ul>
<li>Ultilize multiple processing elements</li>
<li>Specialized processing hardware</li>
</ul>
</li>
<li>Parallel programing
<ul>
<li>Problem partitioning, communication, synchronization</li>
<li>Knowledge of machine characteristics</li>
<li>Understanding data movement</li>
</ul>
</li>
</ul>
<h2 id="a-modern-multi-core-processor">A Modern Multi-Core Processor</h2>
<h3 id="parallelism">Parallelism</h3>
<ul>
<li>simple processor $\rightarrow$ superscalar processor (2 instructions/clock) $\rightarrow$ pre multi-core era processor (larger cache, smarter out-of-order logic, smarter branch predictor, etc.) $\rightarrow$ multi-core era processor</li>
<li>Multi-core era processor
<ul>
<li>Idea #1: use increasing transistor count to add more cores to the processor</li>
<li>Idea #2: amortize cost/complexity of managing an instruction stream across many ALUs
<ul>
<li>SIMD processing: single instruction, multiple data (same instruction broadcast to all ALUs; parallel on all ALUs)</li>
<li>Vector program: realize with AVX intrinsics datatypes and functions (C)
<ul>
<li>Intrinsic functions operate on vectors of $8$ $32$-bit values (e.g. vector of $8$ floats)</li>
<li>Compiled program: processes $8$ array elements simultaneously using vector instructions on $256$-bit vector registers</li>
</ul>
</li>
<li>Data-parallel expression (&ldquo;forall&rdquo; construct)
<ul>
<li>Loop iterations are independent</li>
<li>The same loop body will be executed on a large number of data elements</li>
<li>All the iterations of the loop carry out the exact same sequence of instructions</li>
<li>This abstraction can facilitate automatic generation of both <u>multi-core parallel code</u> and <u>vector instructions</u> to make use of SIMD processing capabilities within a core.</li>
</ul>
</li>
</ul>
</li>
<li>Conditional execution
<ul>
<li>Mask/discard output of ALU</li>
<li>Not all the ALUs do useful work</li>
<li>After branch, continue at full performance</li>
<li>Worse case: $1/8$ peak performance</li>
</ul>
</li>
<li>Coherent execution
<ul>
<li>Property of a program where the <u>same instruction sequence</u> applies to many data elements</li>
<li>Coherent execution is <b>NECESSARY</b> for SIMD processing resources to be used efficiently</li>
<li>Coherent execution is <b>NOT NECESSARY</b> for efficient parallelization across different cores</li>
<li>A lack of instruction stream coherence in a program called &ldquo;divergent&rdquo; execution</li>
</ul>
</li>
<li>SIMD execution: modern CPU examples
<ul>
<li>Instructions are generated by the compiler parallelism requested by programmer using intriinsics</li>
<li>Parallelism conveyed using parallel langurage semantics (&ldquo;forall&rdquo;)</li>
<li>Parallelism inferred by dependency analysis of loops by &ldquo;auto-vectorizing&rdquo; compiler</li>
<li>&ldquo;Explicit SIMD&rdquo;: SIMD parallelization is performed at compile time; can inspect program binary and see SIMD instructions</li>
</ul>
</li>
<li>SIMD execution: modern GPUs
<ul>
<li>&ldquo;Implicit SIMD&rdquo;
<ul>
<li>Compiler generates a binary with scalar instructions</li>
<li>N instances of the program are always run together on the processor</li>
<li><u>Hardware</u> (not compiler) is responsible for simultaneously executing the <u>same instruction</u> from multiple program instances on different data on SIMD ALUs</li>
</ul>
</li>
<li>SIMD width of most modern GPUs ranges from 8 to 32
<ul>
<li>Divergent execution can be a big issue (this means poorly written code might execute at $1/32$ the peak capability of the machine)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Summary: 3 different forms of parallel execution
<ul>
<li>Superscalar
<ul>
<li>Exploit ILP within an instruction stream</li>
<li>Process different instructions from the same instruction stream in parallel (within a core)</li>
<li>Parallelism automatically discovered by the hardware during execution</li>
</ul>
</li>
<li>SIMD
<ul>
<li>Multiple ALUs controlled by the same instruction (within a core)</li>
<li>Efficient for data-parallel workload: amortize control costs over many ALUs</li>
<li>Vectorization done by compiler (explicit SIMD) or at runtime by hardware (implicit SIMD)</li>
</ul>
</li>
<li>Multi-Core
<ul>
<li>Use multiple processing cores</li>
<li>Provides thread-level parallelism: simultaneously execute a completely different instruction stream on each one</li>
<li>Software creates thresds to expose parallelism to hardware (e.g., via threading API)</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Example: paralleism using C++ threads
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#00a8c8">typedef</span> <span style="color:#00a8c8">struct</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00a8c8">int</span> <span style="color:#111">N</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00a8c8">int</span> <span style="color:#111">terms</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">x</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">y</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span> <span style="color:#111">my_args</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">void</span> <span style="color:#75af00">my_thread_func</span><span style="color:#111">(</span><span style="color:#111">my_args</span><span style="color:#f92672">*</span> <span style="color:#111">args</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">sinx</span><span style="color:#111">(</span><span style="color:#111">args</span><span style="color:#f92672">-&gt;</span><span style="color:#111">N</span><span style="color:#111">,</span> <span style="color:#111">args</span><span style="color:#f92672">-&gt;</span><span style="color:#111">terms</span><span style="color:#111">,</span> <span style="color:#111">args</span><span style="color:#f92672">-&gt;</span><span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#111">args</span><span style="color:#f92672">-&gt;</span><span style="color:#111">y</span><span style="color:#111">);</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span><span style="display:flex;"><span><span style="color:#00a8c8">void</span> <span style="color:#75af00">parallel_sinx</span><span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">N</span><span style="color:#111">,</span> <span style="color:#00a8c8">int</span> <span style="color:#111">terms</span><span style="color:#111">,</span> <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">y</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">std</span><span style="color:#f92672">::</span><span style="color:#00a8c8">thread</span> <span style="color:#111">my_thread</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">my_args</span> <span style="color:#111">args</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">N</span> <span style="color:#f92672">=</span> <span style="color:#111">N</span><span style="color:#f92672">/</span><span style="color:#ae81ff">2</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">terms</span> <span style="color:#f92672">=</span> <span style="color:#111">terms</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">x</span> <span style="color:#f92672">=</span> <span style="color:#111">x</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">y</span> <span style="color:#f92672">=</span> <span style="color:#111">y</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// launch thread
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#111">my_thread</span> <span style="color:#f92672">=</span> <span style="color:#111">std</span><span style="color:#f92672">::</span><span style="color:#00a8c8">thread</span><span style="color:#111">(</span><span style="color:#111">my_thread_func</span><span style="color:#111">,</span> <span style="color:#f92672">&amp;</span><span style="color:#111">args</span><span style="color:#111">);</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// on main thread
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#111">sinx</span><span style="color:#111">(</span><span style="color:#111">N</span> <span style="color:#f92672">-</span> <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">N</span><span style="color:#111">,</span> <span style="color:#111">terms</span><span style="color:#111">,</span> <span style="color:#111">x</span> <span style="color:#f92672">+</span> <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">N</span><span style="color:#111">,</span> <span style="color:#111">y</span> <span style="color:#f92672">+</span> <span style="color:#111">args</span><span style="color:#111">.</span><span style="color:#111">N</span><span style="color:#111">);</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// wait for thread to complete
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#111">my_thread</span><span style="color:#111">.</span><span style="color:#111">join</span><span style="color:#111">();</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Data-parallel expression
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#00a8c8">void</span> <span style="color:#75af00">sinx</span><span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">N</span><span style="color:#111">,</span> <span style="color:#00a8c8">int</span> <span style="color:#111">terms</span><span style="color:#111">,</span> <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">y</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">//substitute for (int i = 0; i &lt; N; ++i) { with forall function
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// declares that loop iterations are independent
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// A compiler might automatically generate threaded code for you
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#111">forall</span> <span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">i</span> <span style="color:#111">from</span> <span style="color:#ae81ff">0</span> <span style="color:#111">to</span> <span style="color:#111">N</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">float</span> <span style="color:#111">value</span> <span style="color:#f92672">=</span> <span style="color:#111">x</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">];</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">float</span> <span style="color:#111">numer</span> <span style="color:#f92672">-</span> <span style="color:#111">x</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">]</span> <span style="color:#f92672">*</span> <span style="color:#111">x</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">]</span> <span style="color:#f92672">*</span> <span style="color:#111">x</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">];</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">int</span> <span style="color:#111">denom</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">int</span> <span style="color:#111">sign</span> <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">for</span> <span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">j</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#111">;</span> <span style="color:#111">j</span> <span style="color:#f92672">&lt;=</span> <span style="color:#111">terms</span><span style="color:#111">;</span> <span style="color:#f92672">++</span><span style="color:#111">j</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">y</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">]</span> <span style="color:#f92672">=</span> <span style="color:#111">value</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#272822;background-color:#fafafa;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Vector program (using AVX intrinsics)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e"># include &lt;immintrin.h&gt;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#00a8c8">void</span> <span style="color:#75af00">sinx</span><span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">N</span><span style="color:#111">,</span> <span style="color:#00a8c8">int</span> <span style="color:#111">terms</span><span style="color:#111">,</span> <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">x</span><span style="color:#111">,</span> <span style="color:#00a8c8">float</span><span style="color:#f92672">*</span> <span style="color:#111">y</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00a8c8">float</span> <span style="color:#111">three_fact</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">6</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#00a8c8">for</span> <span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">i</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span><span style="color:#111">;</span> <span style="color:#111">i</span> <span style="color:#f92672">&lt;</span> <span style="color:#111">N</span><span style="color:#111">;</span> <span style="color:#111">i</span> <span style="color:#f92672">+=</span> <span style="color:#ae81ff">8</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">_m256</span> <span style="color:#111">origx</span> <span style="color:#f92672">=</span> <span style="color:#111">_mm256_load_ps</span><span style="color:#111">(</span><span style="color:#ae81ff">8</span><span style="color:#111">x</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">]);</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">_m256</span> <span style="color:#111">value</span> <span style="color:#f92672">=</span> <span style="color:#111">origx</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">_m256</span> <span style="color:#111">numer</span> <span style="color:#f92672">=</span> <span style="color:#111">_mm256_mul_ps</span><span style="color:#111">(</span><span style="color:#111">origx</span><span style="color:#111">,</span> <span style="color:#111">_mm256_mul_ps</span><span style="color:#111">(</span><span style="color:#111">origx</span><span style="color:#111">,</span> <span style="color:#111">origx</span><span style="color:#111">));</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">_m256</span> <span style="color:#111">denom</span> <span style="color:#f92672">=</span> <span style="color:#111">_mm256_broadcast_ss</span><span style="color:#111">(</span><span style="color:#f92672">&amp;</span><span style="color:#111">three_fact</span><span style="color:#111">);</span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">int</span> <span style="color:#111">sign</span> <span style="color:#f92672">=</span> <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#111">;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#00a8c8">for</span> <span style="color:#111">(</span><span style="color:#00a8c8">int</span> <span style="color:#111">j</span> <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#111">;</span> <span style="color:#111">j</span> <span style="color:#f92672">&lt;=</span> <span style="color:#111">terms</span><span style="color:#111">;</span> <span style="color:#f92672">++</span><span style="color:#111">j</span><span style="color:#111">)</span> <span style="color:#111">{</span>
</span></span><span style="display:flex;"><span>    <span style="color:#111">}</span>    
</span></span><span style="display:flex;"><span>  <span style="color:#111">_mm256_store_ps</span><span style="color:#111">(</span><span style="color:#f92672">&amp;</span><span style="color:#111">y</span><span style="color:#111">[</span><span style="color:#111">i</span><span style="color:#111">],</span> <span style="color:#111">value</span><span style="color:#111">);</span>
</span></span><span style="display:flex;"><span>  <span style="color:#111">}</span>
</span></span><span style="display:flex;"><span><span style="color:#111">}</span>
</span></span></code></pre></div><h3 id="accessing-memory">Accessing Memory</h3>
<ul>
<li>Multi-threading reduces stalls (latency)
<ul>
<li>Idea #3: <u>interleave</u> processing of multiple threads on the same core to hide stalls</li>
<li>stall $\rightarrow$ runnable $\rightarrow$ short of time (not executed, core is executing instructions from another thread) $\rightarrow$ running $\rightarrow$ done</li>
<li>Throughput-oriented systems: potentially increase time to complete work by any one thread, in order to increase overall system throughput when running multiple threads</li>
<li>On-chip storage of execution Contexts as a finite resource (L1 cache)
<ul>
<li>with many small contexts (storage for small working set per thread): high latency hiding ability</li>
<li>with large context (storage for large working set per thread): low latency hiding ability</li>
</ul>
</li>
<li>Summary
<ul>
<li>A processor with multiple hardware threads has the ability to avoid stalls by performing instructions from other threads when one thread must wait for a long latency operation to complete</li>
<li>The latency of the memory operation is not changed by multi-threading (No longer causes reduced processor utilization)</li>
<li>A mutli-threaded processor hides memory latency by performing arithmetic from other threads</li>
<li>Programs that feature more arithmetic instructions per meomory access need fewer threads to hide memory stalls</li>
</ul>
</li>
<li>Hardware-supported multi-threading
<ul>
<li>Core manages execution contexts for multiple threads; porcessor makes decision about which thread to run each clock</li>
<li>Interleaved multi-threading (e.g., temporal multi-threading)</li>
<li>Simultaneous multi-threading (SMT, each clock, core chooses instructions from multiple threads to run on ALUs)</li>
</ul>
</li>
</ul>
</li>
<li>Bandwidth
<ul>
<li>Terminology
<ul>
<li>Memory bandwidth</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="parallel-programming-abstractions">Parallel Programming Abstractions</h2>

  </article>

</div>


  
<script type="text/javascript" src="/main.js" defer></script>


</body>

</html>